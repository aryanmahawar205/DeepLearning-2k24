{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8367030,"sourceType":"datasetVersion","datasetId":4973674}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n# Define the dataset path\ndataset_path = '/kaggle/input/diamos-plant-dataset/Pear/leaves'\n\n# Check if the dataset path exists\nif not os.path.exists(dataset_path):\n    print(f\"Error: Dataset path '{dataset_path}' does not exist.\")\nelse:\n    # Count the number of files in each subfolder (Pear and leaves)\n    for folder in os.listdir(dataset_path):\n        folder_path = os.path.join(dataset_path, folder)\n        if os.path.isdir(folder_path):\n            num_files = len(os.listdir(folder_path))\n            print(f\"Number of files in '{folder}' folder: {num_files}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-01T11:51:07.738063Z","iopub.execute_input":"2024-07-01T11:51:07.742240Z","iopub.status.idle":"2024-07-01T11:51:08.428801Z","shell.execute_reply.started":"2024-07-01T11:51:07.742181Z","shell.execute_reply":"2024-07-01T11:51:08.427837Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Number of files in 'curl' folder: 65\nNumber of files in 'healthy' folder: 43\nNumber of files in 'spot' folder: 1768\nNumber of files in 'slug' folder: 4050\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\n\n# Define the path to your dataset\ndataset_path = '/kaggle/input/diamos-plant-dataset/Pear/leaves'\n\n# Define transformations for preprocessing\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize image to 224x224\n    transforms.ToTensor(),  # Convert image to PyTorch tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])  # Normalize image\n\n# Function to check if image is valid\ndef is_valid_image(image_path):\n    try:\n        # Attempt to open and validate the image\n        Image.open(image_path).convert('RGB')\n        return True\n    except (FileNotFoundError, OSError, ValueError):\n        return False\n\n# Custom dataset class with error handling\nclass CustomImageFolder(ImageFolder):\n    def __init__(self, root, transform=None):\n        super().__init__(root, transform=transform)\n\n    def __getitem__(self, index):\n        # Get image path and label from original ImageFolder\n        path, target = self.samples[index]\n\n        # Check if image is valid\n        if not is_valid_image(path):\n            # Handle invalid image (e.g., return a placeholder image or skip)\n            # For simplicity, returning a placeholder image and an out-of-bounds target\n            invalid_image = torch.zeros((3, 224, 224))  # Placeholder image tensor\n            return invalid_image, len(self.classes)  # Return an out-of-bounds target\n\n        # Load and transform the image\n        image = self.loader(path)\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, target\n\n# Load the custom dataset\ndataset = CustomImageFolder(dataset_path, transform=transform)\n\n# Define the DataLoader\nbatch_size = 32\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Define the Channel Shuffle module\nclass ChannelShuffle(nn.Module):\n    def __init__(self, groups):\n        super(ChannelShuffle, self).__init__()\n        self.groups = groups\n\n    def forward(self, x):\n        batchsize, num_channels, height, width = x.data.size()\n        channels_per_group = num_channels // self.groups\n        # Reshape\n        x = x.view(batchsize, self.groups, channels_per_group, height, width)\n        # Transpose\n        x = torch.transpose(x, 1, 2).contiguous()\n        # Flatten\n        x = x.view(batchsize, -1, height, width)\n        return x\n\n# Define the RCSA module\nclass RCSA(nn.Module):\n    def __init__(self, in_channels, reduction=16, groups=4):\n        super(RCSA, self).__init__()\n        self.groups = groups\n        self.channel_shuffle = ChannelShuffle(groups)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.conv1 = nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        residual = x\n        # Channel Shuffle\n        x = self.channel_shuffle(x)\n        # Squeeze and Excitation\n        x = self.avg_pool(x)\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.sigmoid(x)\n        # Scale\n        x = residual * x\n        return x\n\n# Define your custom CNN architecture with RCSA\nclass CustomCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.rcsa1 = RCSA(16)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.rcsa2 = RCSA(32)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(32 * 56 * 56, 128)  # Adjust input size based on your image dimensions after pooling\n        self.fc2 = nn.Linear(128, num_classes)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.rcsa1(x)\n        x = self.pool1(x)\n        x = self.relu(self.conv2(x))\n        x = self.rcsa2(x)\n        x = self.pool2(x)\n        x = x.view(-1, 32 * 56 * 56)  # Adjust based on your image dimensions after pooling\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Initialize the model\nmodel = CustomCNN(num_classes=len(dataset.classes))\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss(ignore_index=len(dataset.classes))  # Ignore the out-of-bounds target\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Function to calculate accuracy\ndef calculate_accuracy(outputs, labels):\n    _, predicted = torch.max(outputs, 1)\n    correct = (predicted == labels).sum().item()\n    total = labels.size(0)\n    accuracy = correct / total * 100\n    return accuracy\n\n# Train the model\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n    for i, (images, labels) in enumerate(data_loader):\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n        # Calculate accuracy\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\n        if (i+1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(data_loader)}], Loss: {running_loss / 10:.4f}')\n            running_loss = 0.0\n\n    # Print accuracy after each epoch\n    epoch_accuracy = total_correct / total_samples * 100\n    print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {epoch_accuracy:.2f}%')\n\nprint('Finished Training.')\n\n# Save the trained model if needed\ntorch.save(model.state_dict(), 'custom_cnn_with_rcsa.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}