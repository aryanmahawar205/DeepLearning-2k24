{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8367030,"sourceType":"datasetVersion","datasetId":4973674}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n# Define the dataset path\ndataset_path = '/kaggle/input/diamos-plant-dataset/Pear/leaves'\n\n# Check if the dataset path exists\nif not os.path.exists(dataset_path):\n    print(f\"Error: Dataset path '{dataset_path}' does not exist.\")\nelse:\n    # Count the number of files in each subfolder (Pear and leaves)\n    for folder in os.listdir(dataset_path):\n        folder_path = os.path.join(dataset_path, folder)\n        if os.path.isdir(folder_path):\n            num_files = len(os.listdir(folder_path))\n            print(f\"Number of files in '{folder}' folder: {num_files}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom PIL import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the path to your dataset\ndataset_path = '/kaggle/input/diamos-plant-dataset/Pear/leaves'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define transformations for preprocessing\ntransform = transforms.Compose([\ntransforms.Resize((224, 224)), # Resize image to 224x224\ntransforms.ToTensor(), # Convert image to PyTorch tensor\ntransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) # Normalize image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to check if image is valid\ndef is_valid_image(image_path):\n    try:\n        # Attempt to open and validate the image\n        Image.open(image_path).convert('RGB')\n        return True\n    except (FileNotFoundError, OSError, ValueError):\n        return False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom dataset class with error handling\nclass CustomImageFolder(ImageFolder):\n    def __init__(self, root, transform=None):\n        super().__init__(root, transform=transform)\n\n    def __getitem__(self, index):\n        # Get image path and label from original ImageFolder\n        path, target = self.samples[index]\n\n        # Check if image is valid\n        if not is_valid_image(path):\n            # Handle invalid image (e.g., return a placeholder image or skip)\n            # For simplicity, returning a placeholder image and an out-of-bounds target\n            invalid_image = torch.zeros((3, 224, 224))  # Placeholder image tensor\n            return invalid_image, len(self.classes)  # Return an out-of-bounds target\n\n        # Load and transform the image\n        image = self.loader(path)\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the custom dataset\ndataset = CustomImageFolder(dataset_path, transform=transform)\n\n# Define the DataLoader\nbatch_size = 32\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the custom CNN model\nclass CustomCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(32 * 56 * 56, 128)  # Adjust input size based on your image dimensions after pooling\n        self.fc2 = nn.Linear(128, num_classes)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.pool(x)\n        x = self.relu(self.conv2(x))\n        x = self.pool(x)\n        x = x.view(-1, 32 * 56 * 56)  # Adjust based on your image dimensions after pooling\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nmodel = CustomCNN(num_classes=len(dataset.classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss(ignore_index=len(dataset.classes)) # Ignore the out-of-bounds target\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for i, (images, labels) in enumerate(data_loader):\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n        if (i+1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(data_loader)}], Loss: {running_loss / 10:.4f}')\n            running_loss = 0.0\n\nprint('Finished Training.')\n\n# Save the trained model if needed\ntorch.save(model.state_dict(), 'custom_cnn.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}